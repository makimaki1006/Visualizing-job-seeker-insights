# -*- coding: utf-8 -*-
"""V3 CSVåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆï¼ˆultrathinkãƒ¢ãƒ¼ãƒ‰ï¼‰

4éšå±¤ã®ãƒ†ã‚¹ãƒˆã‚’10å›ç¹°ã‚Šè¿”ã—å®Ÿè¡Œ:
1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ: å€‹åˆ¥é–¢æ•°ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ¤œè¨¼
2. çµ±åˆãƒ†ã‚¹ãƒˆ: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€£æºã®æ¤œè¨¼
3. E2Eãƒ†ã‚¹ãƒˆ: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã®æ¤œè¨¼
4. å›å¸°ãƒ†ã‚¹ãƒˆ: éå»ã®ãƒã‚°å†ç™ºç¢ºèª

ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: ã€Œãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆã€çµ±åˆãƒ†ã‚¹ãƒˆã€E2Eãƒ†ã‚¹ãƒˆã€å›å¸°ãƒ†ã‚¹ãƒˆã‚’
              ultrathinkã§å¾¹åº•çš„ã«10å›ç¹°ã‚Šè¿”ã—ã¦ç¢ºèªã—ã¦ãã ã•ã„ã€
"""
import sys
import io
import pandas as pd
import hashlib
import json
from pathlib import Path
from datetime import datetime
import traceback

# Windowsç’°å¢ƒã§ã®çµµæ–‡å­—å‡ºåŠ›å¯¾å¿œ
try:
    if hasattr(sys.stdout, 'buffer'):
        sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')
except (ValueError, AttributeError):
    pass


class V3TestSuite:
    """V3 CSVåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆ"""

    def __init__(self):
        self.test_results = []
        self.current_iteration = 0
        self.base_path = Path(__file__).parent
        self.output_csv = self.base_path / 'data/output_v2/mapcomplete_complete_sheets/MapComplete_Complete_All_FIXED.csv'

    def safe_print(self, *args, **kwargs):
        """å®‰å…¨ãªprintï¼ˆstdoutã‚¨ãƒ©ãƒ¼ã‚’ç„¡è¦–ï¼‰"""
        try:
            print(*args, **kwargs)
        except (ValueError, IOError):
            pass

    def calculate_md5(self, file_path):
        """ãƒ•ã‚¡ã‚¤ãƒ«ã®MD5ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
        hash_md5 = hashlib.md5()
        with open(file_path, "rb") as f:
            for chunk in iter(lambda: f.read(4096), b""):
                hash_md5.update(chunk)
        return hash_md5.hexdigest()

    def log_test(self, category, test_name, result, details=""):
        """ãƒ†ã‚¹ãƒˆçµæœã‚’ãƒ­ã‚°"""
        status = "PASS" if result else "FAIL"
        self.test_results.append({
            'iteration': self.current_iteration,
            'category': category,
            'test_name': test_name,
            'status': status,
            'details': details,
            'timestamp': datetime.now().isoformat()
        })
        symbol = "âœ…" if result else "âŒ"
        try:
            self.safe_print(f"    {symbol} [{category}] {test_name}: {status}")
            if details and not result:
                self.safe_print(f"       è©³ç´°: {details}")
        except (ValueError, IOError):
            # stdout already closed
            pass
        return result

    # ============================================================
    # 1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
    # ============================================================

    def test_unit_desired_area_filter(self):
        """ãƒ¦ãƒ‹ãƒƒãƒˆ: DESIRED_AREA_PATTERNãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é–¢æ•°ãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [UNIT] DESIRED_AREA_PATTERNãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¤œè¨¼")

        try:
            # ãƒ¢ãƒƒã‚¯ãƒ‡ãƒ¼ã‚¿ã§40+ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ
            mock_areas_40plus = [(f'éƒ½é“åºœçœŒ{i}', f'å¸‚åŒºç”ºæ‘{i}') for i in range(40)]
            if len(mock_areas_40plus) >= 40:
                self.log_test('UNIT', '40+ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶åˆ¤å®š', True, f"{len(mock_areas_40plus)}ä»¶ >= 40ä»¶")
            else:
                self.log_test('UNIT', '40+ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶åˆ¤å®š', False, f"{len(mock_areas_40plus)}ä»¶ < 40ä»¶")

            # 5éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ãƒ†ã‚¹ãƒˆ
            mock_areas_5pref = [('æ±äº¬éƒ½', 'åŒº1'), ('å¤§é˜ªåºœ', 'å¸‚1'), ('äº¬éƒ½åºœ', 'å¸‚2'),
                               ('ç¥å¥ˆå·çœŒ', 'å¸‚3'), ('æ„›çŸ¥çœŒ', 'å¸‚4')]
            unique_prefs = set(area[0] for area in mock_areas_5pref)
            if len(unique_prefs) >= 5:
                self.log_test('UNIT', '5éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶åˆ¤å®š', True, f"{len(unique_prefs)}éƒ½é“åºœçœŒ >= 5")
            else:
                self.log_test('UNIT', '5éƒ½é“åºœçœŒãƒ•ã‚£ãƒ«ã‚¿ãƒ¼æ¡ä»¶åˆ¤å®š', False, f"{len(unique_prefs)}éƒ½é“åºœçœŒ < 5")

            return True
        except Exception as e:
            self.log_test('UNIT', 'DESIRED_AREA_PATTERNãƒ•ã‚£ãƒ«ã‚¿ãƒ¼', False, str(e))
            return False

    def test_unit_data_normalization(self):
        """ãƒ¦ãƒ‹ãƒƒãƒˆ: ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–é–¢æ•°ãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [UNIT] ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–æ¤œè¨¼")

        try:
            # éƒ½é“åºœçœŒå½¢å¼ãƒã‚§ãƒƒã‚¯
            valid_prefs = ['æ±äº¬éƒ½', 'å¤§é˜ªåºœ', 'äº¬éƒ½åºœ', 'ç¥å¥ˆå·çœŒ']
            invalid_prefs = ['æ±äº¬', 'å¤§é˜ª', 'Tokyo']

            valid_count = sum(1 for p in valid_prefs if p.endswith(('éƒ½', 'é“', 'åºœ', 'çœŒ')))
            invalid_count = sum(1 for p in invalid_prefs if not p.endswith(('éƒ½', 'é“', 'åºœ', 'çœŒ')))

            self.log_test('UNIT', 'éƒ½é“åºœçœŒå½¢å¼æ¤œè¨¼ï¼ˆæ­£å¸¸ç³»ï¼‰', valid_count == len(valid_prefs),
                         f"{valid_count}/{len(valid_prefs)}ä»¶")
            self.log_test('UNIT', 'éƒ½é“åºœçœŒå½¢å¼æ¤œè¨¼ï¼ˆç•°å¸¸ç³»ï¼‰', invalid_count == len(invalid_prefs),
                         f"{invalid_count}/{len(invalid_prefs)}ä»¶æ¤œå‡º")

            return True
        except Exception as e:
            self.log_test('UNIT', 'ãƒ‡ãƒ¼ã‚¿æ­£è¦åŒ–', False, str(e))
            return False

    def test_unit_hash_calculation(self):
        """ãƒ¦ãƒ‹ãƒƒãƒˆ: ãƒãƒƒã‚·ãƒ¥è¨ˆç®—é–¢æ•°ãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [UNIT] ãƒãƒƒã‚·ãƒ¥è¨ˆç®—æ¤œè¨¼")

        try:
            if not self.output_csv.exists():
                self.log_test('UNIT', 'ãƒãƒƒã‚·ãƒ¥è¨ˆç®—ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            hash1 = self.calculate_md5(self.output_csv)
            hash2 = self.calculate_md5(self.output_csv)

            self.log_test('UNIT', 'ãƒãƒƒã‚·ãƒ¥ä¸€è²«æ€§æ¤œè¨¼', hash1 == hash2,
                         f"hash1={hash1[:8]}... == hash2={hash2[:8]}...")

            return hash1 == hash2
        except Exception as e:
            self.log_test('UNIT', 'ãƒãƒƒã‚·ãƒ¥è¨ˆç®—', False, str(e))
            return False

    # ============================================================
    # 2. çµ±åˆãƒ†ã‚¹ãƒˆ
    # ============================================================

    def test_integration_module_imports(self):
        """çµ±åˆ: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆé€£æºãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [INTEGRATION] ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆæ¤œè¨¼")

        try:
            # run_complete_v2_perfect ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            sys.path.insert(0, str(self.base_path.parent / 'reflex_app'))
            sys.path.insert(0, str(self.base_path))

            import run_complete_v2_perfect as v2
            self.log_test('INTEGRATION', 'run_complete_v2_perfect ã‚¤ãƒ³ãƒãƒ¼ãƒˆ', True)

            # ãƒ‘ã‚¿ãƒ¼ãƒ³ç”Ÿæˆãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆ
            from generate_desired_area_pattern import generate_desired_area_pattern
            self.log_test('INTEGRATION', 'generate_desired_area_pattern ã‚¤ãƒ³ãƒãƒ¼ãƒˆ', True)

            from generate_mobility_pattern import generate_mobility_pattern
            self.log_test('INTEGRATION', 'generate_mobility_pattern ã‚¤ãƒ³ãƒãƒ¼ãƒˆ', True)

            from generate_residence_flow import generate_residence_flow
            self.log_test('INTEGRATION', 'generate_residence_flow ã‚¤ãƒ³ãƒãƒ¼ãƒˆ', True)

            from generate_qualification_detail import generate_qualification_detail
            self.log_test('INTEGRATION', 'generate_qualification_detail ã‚¤ãƒ³ãƒãƒ¼ãƒˆ', True)

            return True
        except Exception as e:
            self.log_test('INTEGRATION', 'ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆ', False, str(e))
            traceback.print_exc()
            return False

    def test_integration_data_flow(self):
        """çµ±åˆ: ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼é€£æºãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [INTEGRATION] ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼æ¤œè¨¼")

        try:
            if not self.output_csv.exists():
                self.log_test('INTEGRATION', 'ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            df = pd.read_csv(self.output_csv, encoding='utf-8-sig', low_memory=False)

            # å¿…é ˆã‚«ãƒ©ãƒ ã®å­˜åœ¨ç¢ºèª
            required_cols = ['row_type', 'prefecture', 'municipality', 'category1', 'count']
            missing_cols = [col for col in required_cols if col not in df.columns]

            self.log_test('INTEGRATION', 'å¿…é ˆã‚«ãƒ©ãƒ å­˜åœ¨ç¢ºèª', len(missing_cols) == 0,
                         f"æ¬ æã‚«ãƒ©ãƒ : {missing_cols}" if missing_cols else "ã™ã¹ã¦å­˜åœ¨")

            # row_typeåˆ¥ãƒ‡ãƒ¼ã‚¿é€£æºç¢ºèª
            expected_types = [
                'DESIRED_AREA_PATTERN', 'PERSONA_MUNI', 'EMPLOYMENT_AGE_CROSS',
                'QUALIFICATION_DETAIL', 'MOBILITY_PATTERN', 'RESIDENCE_FLOW',
                'CAREER_CROSS', 'SUMMARY', 'AGE_GENDER', 'PERSONA'
            ]

            actual_types = df['row_type'].unique().tolist()
            missing_types = [t for t in expected_types if t not in actual_types]

            self.log_test('INTEGRATION', 'row_typeå®Œå…¨æ€§ç¢ºèª', len(missing_types) == 0,
                         f"æ¬ æå‹: {missing_types}" if missing_types else "ã™ã¹ã¦å­˜åœ¨")

            return len(missing_cols) == 0 and len(missing_types) == 0
        except Exception as e:
            self.log_test('INTEGRATION', 'ãƒ‡ãƒ¼ã‚¿ãƒ•ãƒ­ãƒ¼', False, str(e))
            traceback.print_exc()
            return False

    def test_integration_output_consistency(self):
        """çµ±åˆ: å‡ºåŠ›ãƒ‡ãƒ¼ã‚¿ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [INTEGRATION] å‡ºåŠ›ä¸€è²«æ€§æ¤œè¨¼")

        try:
            if not self.output_csv.exists():
                self.log_test('INTEGRATION', 'å‡ºåŠ›ä¸€è²«æ€§ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            df = pd.read_csv(self.output_csv, encoding='utf-8-sig', low_memory=False)

            # ç·è¡Œæ•°ç¢ºèª
            expected_total = 53000
            actual_total = len(df)
            self.log_test('INTEGRATION', 'ç·è¡Œæ•°ä¸€è²«æ€§', actual_total == expected_total,
                         f"æœŸå¾…={expected_total:,}, å®Ÿéš›={actual_total:,}")

            # DESIRED_AREA_PATTERNè¡Œæ•°ç¢ºèª
            expected_dap = 26768
            actual_dap = len(df[df['row_type'] == 'DESIRED_AREA_PATTERN'])
            self.log_test('INTEGRATION', 'DESIRED_AREA_PATTERNè¡Œæ•°ä¸€è²«æ€§', actual_dap == expected_dap,
                         f"æœŸå¾…={expected_dap:,}, å®Ÿéš›={actual_dap:,}")

            return actual_total == expected_total and actual_dap == expected_dap
        except Exception as e:
            self.log_test('INTEGRATION', 'å‡ºåŠ›ä¸€è²«æ€§', False, str(e))
            traceback.print_exc()
            return False

    # ============================================================
    # 3. E2Eãƒ†ã‚¹ãƒˆ
    # ============================================================

    def test_e2e_full_execution(self):
        """E2E: å®Œå…¨å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [E2E] å®Œå…¨å®Ÿè¡Œãƒ•ãƒ­ãƒ¼æ¤œè¨¼")

        try:
            if not self.output_csv.exists():
                self.log_test('E2E', 'å®Œå…¨å®Ÿè¡Œï¼ˆæœ€çµ‚CSVç”Ÿæˆï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
            self.log_test('E2E', 'æœ€çµ‚CSVç”Ÿæˆç¢ºèª', True, f"{self.output_csv.name}")

            # ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ç¢ºèª
            df = pd.read_csv(self.output_csv, encoding='utf-8-sig', low_memory=False)
            self.log_test('E2E', 'CSVèª­ã¿è¾¼ã¿æˆåŠŸ', True, f"{len(df):,}è¡Œèª­ã¿è¾¼ã¿")

            # ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª
            has_data = len(df) > 0
            has_row_type = 'row_type' in df.columns
            has_prefecture = 'prefecture' in df.columns

            self.log_test('E2E', 'ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ç¢ºèª', has_data and has_row_type and has_prefecture,
                         f"è¡Œæ•°={len(df):,}, row_typeå­˜åœ¨={has_row_type}, prefectureå­˜åœ¨={has_prefecture}")

            return has_data and has_row_type and has_prefecture
        except Exception as e:
            self.log_test('E2E', 'å®Œå…¨å®Ÿè¡Œãƒ•ãƒ­ãƒ¼', False, str(e))
            traceback.print_exc()
            return False

    def test_e2e_hash_consistency(self):
        """E2E: ãƒãƒƒã‚·ãƒ¥ä¸€è²«æ€§ãƒ†ã‚¹ãƒˆï¼ˆ10å›ç¹°ã‚Šè¿”ã—ï¼‰"""
        self.safe_print("\n  [E2E] ãƒãƒƒã‚·ãƒ¥ä¸€è²«æ€§æ¤œè¨¼ï¼ˆ10å›ç¹°ã‚Šè¿”ã—å†…ã§ã®ä¸€è²«æ€§ï¼‰")

        try:
            if not self.output_csv.exists():
                self.log_test('E2E', 'ãƒãƒƒã‚·ãƒ¥ä¸€è²«æ€§ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            # ç¾åœ¨ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã§ã®ãƒãƒƒã‚·ãƒ¥å–å¾—
            current_hash = self.calculate_md5(self.output_csv)

            # åˆå›ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã®å ´åˆã€åŸºæº–ãƒãƒƒã‚·ãƒ¥ã¨ã—ã¦ä¿å­˜
            if self.current_iteration == 1:
                self.baseline_hash = current_hash
                self.log_test('E2E', 'ãƒãƒƒã‚·ãƒ¥åŸºæº–å€¤è¨­å®š', True, f"baseline={current_hash[:16]}...")
                return True

            # 2å›ç›®ä»¥é™ã¯åŸºæº–ãƒãƒƒã‚·ãƒ¥ã¨æ¯”è¼ƒ
            is_consistent = current_hash == self.baseline_hash
            self.log_test('E2E', f'ãƒãƒƒã‚·ãƒ¥ä¸€è²«æ€§ï¼ˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³{self.current_iteration}ï¼‰',
                         is_consistent,
                         f"current={current_hash[:16]}... vs baseline={self.baseline_hash[:16]}...")

            return is_consistent
        except Exception as e:
            self.log_test('E2E', 'ãƒãƒƒã‚·ãƒ¥ä¸€è²«æ€§', False, str(e))
            traceback.print_exc()
            return False

    def test_e2e_data_quality(self):
        """E2E: ãƒ‡ãƒ¼ã‚¿å“è³ªç·åˆãƒ†ã‚¹ãƒˆ"""
        self.safe_print("\n  [E2E] ãƒ‡ãƒ¼ã‚¿å“è³ªç·åˆæ¤œè¨¼")

        try:
            if not self.output_csv.exists():
                self.log_test('E2E', 'ãƒ‡ãƒ¼ã‚¿å“è³ªï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            df = pd.read_csv(self.output_csv, encoding='utf-8-sig', low_memory=False)

            # é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯
            duplicates = df.duplicated().sum()
            self.log_test('E2E', 'é‡è¤‡è¡Œãªã—ç¢ºèª', duplicates == 0,
                         f"é‡è¤‡è¡Œ={duplicates}ä»¶")

            # éƒ½é“åºœçœŒã‚«ãƒãƒ¬ãƒƒã‚¸
            unique_prefs = df['prefecture'].dropna().nunique()
            self.log_test('E2E', 'éƒ½é“åºœçœŒã‚«ãƒãƒ¬ãƒƒã‚¸', unique_prefs == 47,
                         f"{unique_prefs}/47éƒ½é“åºœçœŒ")

            # ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
            is_numeric = pd.api.types.is_numeric_dtype(df['count'])
            self.log_test('E2E', 'countæ•°å€¤å‹ç¢ºèª', is_numeric,
                         f"æ•°å€¤å‹={is_numeric}")

            return duplicates == 0 and unique_prefs == 47 and is_numeric
        except Exception as e:
            self.log_test('E2E', 'ãƒ‡ãƒ¼ã‚¿å“è³ªç·åˆ', False, str(e))
            traceback.print_exc()
            return False

    # ============================================================
    # 4. å›å¸°ãƒ†ã‚¹ãƒˆ
    # ============================================================

    def test_regression_gender_keyerror(self):
        """å›å¸°: gender KeyErrorãƒã‚°å†ç™ºç¢ºèª"""
        self.safe_print("\n  [REGRESSION] gender KeyErrorå›å¸°ãƒ†ã‚¹ãƒˆ")

        try:
            if not self.output_csv.exists():
                self.log_test('REGRESSION', 'gender KeyErrorï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            df = pd.read_csv(self.output_csv, encoding='utf-8-sig', low_memory=False)

            # AGE_GENDERãƒ‡ãƒ¼ã‚¿ãŒå­˜åœ¨ã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆgenderå‡¦ç†ãŒæˆåŠŸã—ã¦ã„ã‚‹è¨¼æ‹ ï¼‰
            age_gender_count = len(df[df['row_type'] == 'AGE_GENDER'])
            has_age_gender = age_gender_count > 0

            self.log_test('REGRESSION', 'genderå‡¦ç†æˆåŠŸç¢ºèªï¼ˆAGE_GENDERãƒ‡ãƒ¼ã‚¿å­˜åœ¨ï¼‰',
                         has_age_gender,
                         f"AGE_GENDER={age_gender_count}è¡Œ")

            # category2ã«æ€§åˆ¥ãƒ‡ãƒ¼ã‚¿ãŒå«ã¾ã‚Œã‚‹ã“ã¨ã‚’ç¢ºèª
            if has_age_gender:
                age_gender_df = df[df['row_type'] == 'AGE_GENDER']
                gender_values = age_gender_df['category2'].dropna().unique()
                has_gender_data = len(gender_values) > 0

                self.log_test('REGRESSION', 'gender ãƒ‡ãƒ¼ã‚¿æ­£å¸¸å‡¦ç†ç¢ºèª',
                             has_gender_data,
                             f"æ€§åˆ¥ã‚«ãƒ†ã‚´ãƒªæ•°={len(gender_values)}")

                return has_gender_data

            return has_age_gender
        except Exception as e:
            self.log_test('REGRESSION', 'gender KeyErrorå›å¸°', False, str(e))
            traceback.print_exc()
            return False

    def test_regression_stdout_error(self):
        """å›å¸°: sys.stdoutã‚¨ãƒ©ãƒ¼ãƒã‚°å†ç™ºç¢ºèª"""
        self.safe_print("\n  [REGRESSION] sys.stdoutã‚¨ãƒ©ãƒ¼å›å¸°ãƒ†ã‚¹ãƒˆ")

        try:
            # ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã‚¤ãƒ³ãƒãƒ¼ãƒˆãŒæˆåŠŸã™ã‚‹ã“ã¨ã‚’ç¢ºèªï¼ˆstdoutå•é¡ŒãŒè§£æ±ºã—ã¦ã„ã‚‹è¨¼æ‹ ï¼‰
            sys.path.insert(0, str(self.base_path))

            # ã“ã‚Œã‚‰ã®ã‚¤ãƒ³ãƒãƒ¼ãƒˆã§stdoutã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ãªã„ã“ã¨ã‚’ç¢ºèª
            from generate_desired_area_pattern import generate_desired_area_pattern
            from generate_mobility_pattern import generate_mobility_pattern
            from generate_residence_flow import generate_residence_flow
            from generate_qualification_detail import generate_qualification_detail

            self.log_test('REGRESSION', 'sys.stdoutã‚¨ãƒ©ãƒ¼å›å¸°ãªã—ï¼ˆã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸï¼‰', True,
                         "4ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã™ã¹ã¦ã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")

            return True
        except ValueError as e:
            if "I/O operation on closed file" in str(e):
                self.log_test('REGRESSION', 'sys.stdoutã‚¨ãƒ©ãƒ¼å›å¸°æ¤œå‡º', False, str(e))
                return False
            raise
        except Exception as e:
            self.log_test('REGRESSION', 'sys.stdoutã‚¨ãƒ©ãƒ¼å›å¸°ãƒ†ã‚¹ãƒˆ', False, str(e))
            traceback.print_exc()
            return False

    def test_regression_import_path(self):
        """å›å¸°: ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼ãƒã‚°å†ç™ºç¢ºèª"""
        self.safe_print("\n  [REGRESSION] ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼å›å¸°ãƒ†ã‚¹ãƒˆ")

        try:
            # sys.pathèª¿æ•´ãŒæ­£ã—ãå‹•ä½œã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            sys.path.insert(0, str(self.base_path.parent / 'reflex_app'))
            sys.path.insert(0, str(self.base_path))

            # run_complete_v2_perfectãŒã‚¤ãƒ³ãƒãƒ¼ãƒˆã§ãã‚‹ã“ã¨ã‚’ç¢ºèª
            import run_complete_v2_perfect as v2

            self.log_test('REGRESSION', 'ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼å›å¸°ãªã—', True,
                         "run_complete_v2_perfectã‚¤ãƒ³ãƒãƒ¼ãƒˆæˆåŠŸ")

            return True
        except ModuleNotFoundError as e:
            self.log_test('REGRESSION', 'ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼å›å¸°æ¤œå‡º', False, str(e))
            return False
        except Exception as e:
            self.log_test('REGRESSION', 'ã‚¤ãƒ³ãƒãƒ¼ãƒˆãƒ‘ã‚¹ã‚¨ãƒ©ãƒ¼å›å¸°ãƒ†ã‚¹ãƒˆ', False, str(e))
            traceback.print_exc()
            return False

    def test_regression_outlier_filter(self):
        """å›å¸°: å¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‹•ä½œç¢ºèª"""
        self.safe_print("\n  [REGRESSION] å¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å›å¸°ãƒ†ã‚¹ãƒˆ")

        try:
            if not self.output_csv.exists():
                self.log_test('REGRESSION', 'å¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼ï¼ˆãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ï¼‰', False, "CSVãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“")
                return False

            df = pd.read_csv(self.output_csv, encoding='utf-8-sig', low_memory=False)

            # DESIRED_AREA_PATTERNã®è¡Œæ•°ãŒæœŸå¾…å€¤ï¼ˆãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œï¼‰ã¨ä¸€è‡´ã™ã‚‹ã“ã¨ã‚’ç¢ºèª
            expected_dap = 26768  # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å¾Œã®æœŸå¾…å€¤
            actual_dap = len(df[df['row_type'] == 'DESIRED_AREA_PATTERN'])

            is_filtered = actual_dap == expected_dap

            self.log_test('REGRESSION', 'å¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‹•ä½œç¢ºèªï¼ˆ40+/5éƒ½é“åºœçœŒï¼‰',
                         is_filtered,
                         f"æœŸå¾…={expected_dap:,}, å®Ÿéš›={actual_dap:,}")

            # ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å‰ã®è¡Œæ•°ï¼ˆ31,445è¡Œï¼‰ã‚ˆã‚Šæ¸›å°‘ã—ã¦ã„ã‚‹ã“ã¨ã‚’ç¢ºèª
            before_filter = 31445
            is_reduced = actual_dap < before_filter

            self.log_test('REGRESSION', 'å¤–ã‚Œå€¤é™¤å¤–ç¢ºèª',
                         is_reduced,
                         f"å‰Šæ¸›å‰={before_filter:,} â†’ å‰Šæ¸›å¾Œ={actual_dap:,} (å‰Šæ¸›ç‡={(before_filter-actual_dap)/before_filter*100:.1f}%)")

            return is_filtered and is_reduced
        except Exception as e:
            self.log_test('REGRESSION', 'å¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼å›å¸°', False, str(e))
            traceback.print_exc()
            return False

    # ============================================================
    # ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆå®Ÿè¡Œ
    # ============================================================

    def run_iteration(self, iteration):
        """1å›ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        self.current_iteration = iteration

        self.safe_print(f"\n{'=' * 60}")
        self.safe_print(f"ãƒ†ã‚¹ãƒˆã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {iteration}/10")
        self.safe_print('=' * 60)

        # ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ
        self.safe_print("\n[1/4] ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        self.test_unit_desired_area_filter()
        self.test_unit_data_normalization()
        self.test_unit_hash_calculation()

        # çµ±åˆãƒ†ã‚¹ãƒˆ
        self.safe_print("\n[2/4] çµ±åˆãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        self.test_integration_module_imports()
        self.test_integration_data_flow()
        self.test_integration_output_consistency()

        # E2Eãƒ†ã‚¹ãƒˆ
        self.safe_print("\n[3/4] E2Eãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        self.test_e2e_full_execution()
        self.test_e2e_hash_consistency()
        self.test_e2e_data_quality()

        # å›å¸°ãƒ†ã‚¹ãƒˆ
        self.safe_print("\n[4/4] å›å¸°ãƒ†ã‚¹ãƒˆå®Ÿè¡Œä¸­...")
        self.test_regression_gender_keyerror()
        self.test_regression_stdout_error()
        self.test_regression_import_path()
        self.test_regression_outlier_filter()

        self.safe_print(f"\n{'=' * 60}")
        self.safe_print(f"âœ… ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {iteration}/10 å®Œäº†")
        self.safe_print('=' * 60)

    def run_all_iterations(self):
        """10å›ã®ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ã‚’å®Ÿè¡Œ"""
        self.safe_print("=" * 60)
        self.safe_print("V3 CSVåŒ…æ‹¬çš„ãƒ†ã‚¹ãƒˆã‚¹ã‚¤ãƒ¼ãƒˆï¼ˆultrathinkãƒ¢ãƒ¼ãƒ‰ï¼‰")
        self.safe_print("=" * 60)
        self.safe_print("\nãƒ†ã‚¹ãƒˆéšå±¤:")
        self.safe_print("  1. ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ: å€‹åˆ¥é–¢æ•°ãƒ»ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«ã®æ¤œè¨¼")
        self.safe_print("  2. çµ±åˆãƒ†ã‚¹ãƒˆ: ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ«é–“é€£æºã®æ¤œè¨¼")
        self.safe_print("  3. E2Eãƒ†ã‚¹ãƒˆ: ã‚¨ãƒ³ãƒ‰ãƒ„ãƒ¼ã‚¨ãƒ³ãƒ‰å®Ÿè¡Œãƒ•ãƒ­ãƒ¼ã®æ¤œè¨¼")
        self.safe_print("  4. å›å¸°ãƒ†ã‚¹ãƒˆ: éå»ã®ãƒã‚°å†ç™ºç¢ºèª")
        self.safe_print("\nå®Ÿè¡Œå›æ•°: 10å›ç¹°ã‚Šè¿”ã—")
        self.safe_print("=" * 60)

        for i in range(1, 11):
            self.run_iteration(i)

        self.generate_final_report()

    def generate_final_report(self):
        """æœ€çµ‚ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        self.safe_print("\n" + "=" * 60)
        self.safe_print("æœ€çµ‚ãƒ†ã‚¹ãƒˆãƒ¬ãƒãƒ¼ãƒˆ")
        self.safe_print("=" * 60)

        # ç·ãƒ†ã‚¹ãƒˆæ•°ã¨ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        total_tests = len(self.test_results)
        passed = sum(1 for r in self.test_results if r['status'] == 'PASS')
        failed = total_tests - passed

        self.safe_print(f"\nç·ãƒ†ã‚¹ãƒˆæ•°: {total_tests}")
        self.safe_print(f"  âœ… æˆåŠŸ: {passed} ({passed/total_tests*100:.1f}%)")
        self.safe_print(f"  âŒ å¤±æ•—: {failed} ({failed/total_tests*100:.1f}%)")

        # ã‚«ãƒ†ã‚´ãƒªåˆ¥é›†è¨ˆ
        self.safe_print("\nã‚«ãƒ†ã‚´ãƒªåˆ¥çµæœ:")
        for category in ['UNIT', 'INTEGRATION', 'E2E', 'REGRESSION']:
            cat_tests = [r for r in self.test_results if r['category'] == category]
            cat_passed = sum(1 for r in cat_tests if r['status'] == 'PASS')
            cat_total = len(cat_tests)

            if cat_total > 0:
                self.safe_print(f"  [{category}] {cat_passed}/{cat_total} æˆåŠŸ ({cat_passed/cat_total*100:.1f}%)")

        # ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥æˆåŠŸç‡
        self.safe_print("\nã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³åˆ¥æˆåŠŸç‡:")
        for i in range(1, 11):
            iter_tests = [r for r in self.test_results if r['iteration'] == i]
            iter_passed = sum(1 for r in iter_tests if r['status'] == 'PASS')
            iter_total = len(iter_tests)

            if iter_total > 0:
                status = "âœ…" if iter_passed == iter_total else "âš ï¸" if iter_passed / iter_total >= 0.8 else "âŒ"
                self.safe_print(f"  ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³ {i:2d}/10: {status} {iter_passed}/{iter_total} æˆåŠŸ ({iter_passed/iter_total*100:.1f}%)")

        # å¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆã®è©³ç´°
        if failed > 0:
            self.safe_print("\nå¤±æ•—ã—ãŸãƒ†ã‚¹ãƒˆ:")
            failed_tests = [r for r in self.test_results if r['status'] == 'FAIL']
            for test in failed_tests[:10]:  # æœ€åˆã®10ä»¶ã®ã¿è¡¨ç¤º
                self.safe_print(f"  âŒ [ã‚¤ãƒ†ãƒ¬ãƒ¼ã‚·ãƒ§ãƒ³{test['iteration']}] [{test['category']}] {test['test_name']}")
                if test['details']:
                    self.safe_print(f"     è©³ç´°: {test['details']}")

        # JSONå‡ºåŠ›
        output_file = self.base_path / 'test_results_v3_comprehensive.json'
        with open(output_file, 'w', encoding='utf-8') as f:
            json.dump(self.test_results, f, ensure_ascii=False, indent=2)

        self.safe_print(f"\nè©³ç´°çµæœã‚’ä¿å­˜: {output_file}")

        # æœ€çµ‚åˆ¤å®š
        self.safe_print("\n" + "=" * 60)
        if failed == 0:
            self.safe_print("ğŸ‰ ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒæˆåŠŸã—ã¾ã—ãŸï¼")
            self.safe_print("=" * 60)
            self.safe_print("\nV3 CSVå®Ÿè£…å“è³ªç¢ºèª:")
            self.safe_print("  âœ… ãƒ¦ãƒ‹ãƒƒãƒˆãƒ†ã‚¹ãƒˆ: ã™ã¹ã¦æˆåŠŸ")
            self.safe_print("  âœ… çµ±åˆãƒ†ã‚¹ãƒˆ: ã™ã¹ã¦æˆåŠŸ")
            self.safe_print("  âœ… E2Eãƒ†ã‚¹ãƒˆ: ã™ã¹ã¦æˆåŠŸ")
            self.safe_print("  âœ… å›å¸°ãƒ†ã‚¹ãƒˆ: ã™ã¹ã¦æˆåŠŸ")
            self.safe_print(f"  âœ… 10å›ç¹°ã‚Šè¿”ã—ãƒ†ã‚¹ãƒˆ: ã™ã¹ã¦æˆåŠŸ")
            self.safe_print("\nç·åˆçµæœ: V3 CSVå®Ÿè£…ã¯æœ¬ç•ªé‹ç”¨å¯èƒ½ãªå“è³ªãƒ¬ãƒ™ãƒ« âœ…")
        else:
            self.safe_print(f"âš ï¸  {failed}ä»¶ã®ãƒ†ã‚¹ãƒˆãŒå¤±æ•—ã—ã¾ã—ãŸ")
            self.safe_print("=" * 60)
            self.safe_print("\næ”¹å–„ãŒå¿…è¦ãªé ˜åŸŸ:")

            # å¤±æ•—ã®å¤šã„ã‚«ãƒ†ã‚´ãƒªã‚’ç‰¹å®š
            for category in ['UNIT', 'INTEGRATION', 'E2E', 'REGRESSION']:
                cat_failed = [r for r in self.test_results
                             if r['category'] == category and r['status'] == 'FAIL']
                if cat_failed:
                    self.safe_print(f"  âš ï¸  [{category}] {len(cat_failed)}ä»¶ã®å¤±æ•—")


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    suite = V3TestSuite()
    suite.run_all_iterations()


if __name__ == '__main__':
    main()
