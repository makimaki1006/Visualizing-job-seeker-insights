#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Phase 12, 13, 14ã®ãƒ†ã‚¹ãƒˆã‚¹ã‚¯ãƒªãƒ—ãƒˆ

ã€ãƒ†ã‚¹ãƒˆå†…å®¹ã€‘
1. å°è¦æ¨¡ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ã§Phase 12-14ã‚’å®Ÿè¡Œ
2. å‡ºåŠ›CSVãƒ•ã‚¡ã‚¤ãƒ«ã®å­˜åœ¨ç¢ºèª
3. CSVãƒ•ã‚¡ã‚¤ãƒ«æ§‹é€ ã®æ¤œè¨¼ï¼ˆã‚«ãƒ©ãƒ åã€ãƒ‡ãƒ¼ã‚¿ä»¶æ•°ï¼‰
4. latitude/longitudeåˆ—ã®å­˜åœ¨ç¢ºèªï¼ˆMAPçµ±åˆå¯¾å¿œï¼‰
5. å“è³ªãƒ¬ãƒãƒ¼ãƒˆã®ç¢ºèª
"""

import sys
from pathlib import Path
import pandas as pd

# å®Ÿãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ç”¨ã—ã¦ãƒ†ã‚¹ãƒˆ
sys.path.insert(0, str(Path(__file__).parent))
from run_complete_v2_perfect import PerfectJobSeekerAnalyzer


def test_phase12_supply_demand_gap():
    """Phase 12: éœ€çµ¦ã‚®ãƒ£ãƒƒãƒ—åˆ†æã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("ã€Phase 12ãƒ†ã‚¹ãƒˆ: éœ€çµ¦ã‚®ãƒ£ãƒƒãƒ—åˆ†æã€‘")
    print("=" * 80)

    # æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    csv_path = Path(r"C:\Users\fuji1\OneDrive\Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆä¿ç®¡\out")
    csv_files = sorted(csv_path.glob("results_*.csv"), reverse=True)

    if not csv_files:
        print("  âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    latest_csv = csv_files[0]
    print(f"  ğŸ“ ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿: {latest_csv.name}")

    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    analyzer = PerfectJobSeekerAnalyzer(str(latest_csv))
    analyzer.load_data()
    analyzer.process_data()

    # Phase 12å®Ÿè¡Œ
    try:
        analyzer.export_phase12()
    except Exception as e:
        print(f"  âŒ Phase 12å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    output_path = Path("data/output_v2/phase12")
    csv_file = output_path / "SupplyDemandGap.csv"
    quality_report = output_path / "P12_QualityReport.csv"

    if not csv_file.exists():
        print(f"  âŒ SupplyDemandGap.csvãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    if not quality_report.exists():
        print(f"  âŒ P12_QualityReport.csvãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
    df = pd.read_csv(csv_file, encoding='utf-8-sig')
    print(f"\n  âœ… SupplyDemandGap.csv: {len(df)}ä»¶")
    print(f"  ğŸ“‹ ã‚«ãƒ©ãƒ : {', '.join(df.columns.tolist())}")

    # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
    required_columns = ['prefecture', 'municipality', 'location', 'demand_count',
                        'supply_count', 'demand_supply_ratio', 'gap', 'latitude', 'longitude']
    missing_columns = [col for col in required_columns if col not in df.columns]

    if missing_columns:
        print(f"  âŒ ä¸è¶³ã‚«ãƒ©ãƒ : {', '.join(missing_columns)}")
        return False

    print(f"  âœ… å¿…é ˆã‚«ãƒ©ãƒ : ã™ã¹ã¦å­˜åœ¨")

    # latitude/longitudeåˆ—ã®ç¢ºèªï¼ˆMAPçµ±åˆå¯¾å¿œï¼‰
    has_coords = df[['latitude', 'longitude']].notna().all(axis=1).sum()
    total = len(df)
    print(f"  ğŸ—ºï¸ åº§æ¨™ãƒ‡ãƒ¼ã‚¿: {has_coords}/{total}ä»¶ ({has_coords/total*100:.1f}%)")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤º
    print(f"\n  ã€Top 5 éœ€çµ¦ã‚®ãƒ£ãƒƒãƒ—ã€‘")
    print(df[['location', 'demand_count', 'supply_count', 'demand_supply_ratio', 'gap']].head().to_string(index=False))

    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
    report_df = pd.read_csv(quality_report, encoding='utf-8-sig')
    print(f"\n  âœ… P12_QualityReport.csv: {len(report_df)}é …ç›®")

    return True


def test_phase13_rarity_score():
    """Phase 13: å¸Œå°‘æ€§ã‚¹ã‚³ã‚¢ã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("ã€Phase 13ãƒ†ã‚¹ãƒˆ: å¸Œå°‘æ€§ã‚¹ã‚³ã‚¢ã€‘")
    print("=" * 80)

    # æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    csv_path = Path(r"C:\Users\fuji1\OneDrive\Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆä¿ç®¡\out")
    csv_files = sorted(csv_path.glob("results_*.csv"), reverse=True)

    if not csv_files:
        print("  âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    latest_csv = csv_files[0]
    print(f"  ğŸ“ ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿: {latest_csv.name}")

    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    analyzer = PerfectJobSeekerAnalyzer(str(latest_csv))
    analyzer.load_data()
    analyzer.process_data()

    # Phase 13å®Ÿè¡Œ
    try:
        analyzer.export_phase13()
    except Exception as e:
        print(f"  âŒ Phase 13å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    output_path = Path("data/output_v2/phase13")
    csv_file = output_path / "RarityScore.csv"
    quality_report = output_path / "P13_QualityReport.csv"

    if not csv_file.exists():
        print(f"  âŒ RarityScore.csvãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    if not quality_report.exists():
        print(f"  âŒ P13_QualityReport.csvãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
    df = pd.read_csv(csv_file, encoding='utf-8-sig')
    print(f"\n  âœ… RarityScore.csv: {len(df)}ä»¶")
    print(f"  ğŸ“‹ ã‚«ãƒ©ãƒ : {', '.join(df.columns.tolist())}")

    # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
    required_columns = ['prefecture', 'municipality', 'location', 'age_bucket', 'gender',
                        'has_national_license', 'count', 'rarity_score', 'rarity_rank',
                        'latitude', 'longitude']
    missing_columns = [col for col in required_columns if col not in df.columns]

    if missing_columns:
        print(f"  âŒ ä¸è¶³ã‚«ãƒ©ãƒ : {', '.join(missing_columns)}")
        return False

    print(f"  âœ… å¿…é ˆã‚«ãƒ©ãƒ : ã™ã¹ã¦å­˜åœ¨")

    # latitude/longitudeåˆ—ã®ç¢ºèªï¼ˆMAPçµ±åˆå¯¾å¿œï¼‰
    has_coords = df[['latitude', 'longitude']].notna().all(axis=1).sum()
    total = len(df)
    print(f"  ğŸ—ºï¸ åº§æ¨™ãƒ‡ãƒ¼ã‚¿: {has_coords}/{total}ä»¶ ({has_coords/total*100:.1f}%)")

    # å¸Œå°‘æ€§ãƒ©ãƒ³ã‚¯åˆ†å¸ƒ
    rank_dist = df['rarity_rank'].value_counts().sort_index()
    print(f"\n  ã€å¸Œå°‘æ€§ãƒ©ãƒ³ã‚¯åˆ†å¸ƒã€‘")
    for rank, count in rank_dist.items():
        print(f"    {rank}: {count}ä»¶")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆæœ€ã‚‚å¸Œå°‘ãªã‚±ãƒ¼ã‚¹ï¼‰
    print(f"\n  ã€Top 5 æœ€ã‚‚å¸Œå°‘ãªã‚±ãƒ¼ã‚¹ã€‘")
    print(df[['location', 'age_bucket', 'gender', 'has_national_license', 'count', 'rarity_score', 'rarity_rank']].head().to_string(index=False))

    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
    report_df = pd.read_csv(quality_report, encoding='utf-8-sig')
    print(f"\n  âœ… P13_QualityReport.csv: {len(report_df)}é …ç›®")

    return True


def test_phase14_competition_profile():
    """Phase 14: ç«¶åˆåˆ†æã®ãƒ†ã‚¹ãƒˆ"""
    print("\n" + "=" * 80)
    print("ã€Phase 14ãƒ†ã‚¹ãƒˆ: ç«¶åˆåˆ†æã€‘")
    print("=" * 80)

    # æœ€æ–°ã®CSVãƒ•ã‚¡ã‚¤ãƒ«ã‚’å–å¾—
    csv_path = Path(r"C:\Users\fuji1\OneDrive\Pythonã‚¹ã‚¯ãƒªãƒ—ãƒˆä¿ç®¡\out")
    csv_files = sorted(csv_path.glob("results_*.csv"), reverse=True)

    if not csv_files:
        print("  âŒ ãƒ†ã‚¹ãƒˆãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
        return False

    latest_csv = csv_files[0]
    print(f"  ğŸ“ ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿: {latest_csv.name}")

    # ã‚¢ãƒŠãƒ©ã‚¤ã‚¶ãƒ¼åˆæœŸåŒ–
    analyzer = PerfectJobSeekerAnalyzer(str(latest_csv))
    analyzer.load_data()
    analyzer.process_data()

    # Phase 14å®Ÿè¡Œ
    try:
        analyzer.export_phase14()
    except Exception as e:
        print(f"  âŒ Phase 14å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
        import traceback
        traceback.print_exc()
        return False

    # å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«ã®ç¢ºèª
    output_path = Path("data/output_v2/phase14")
    csv_file = output_path / "CompetitionProfile.csv"
    quality_report = output_path / "P14_QualityReport.csv"

    if not csv_file.exists():
        print(f"  âŒ CompetitionProfile.csvãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    if not quality_report.exists():
        print(f"  âŒ P14_QualityReport.csvãŒç”Ÿæˆã•ã‚Œã¦ã„ã¾ã›ã‚“")
        return False

    # CSVãƒ•ã‚¡ã‚¤ãƒ«ã®æ¤œè¨¼
    df = pd.read_csv(csv_file, encoding='utf-8-sig')
    print(f"\n  âœ… CompetitionProfile.csv: {len(df)}ä»¶")
    print(f"  ğŸ“‹ ã‚«ãƒ©ãƒ : {', '.join(df.columns.tolist())}")

    # å¿…é ˆã‚«ãƒ©ãƒ ã®ç¢ºèª
    required_columns = ['prefecture', 'municipality', 'location', 'total_applicants',
                        'top_age_group', 'top_age_ratio', 'female_ratio', 'male_ratio',
                        'national_license_rate', 'top_employment_status', 'top_employment_ratio',
                        'avg_qualification_count', 'latitude', 'longitude']
    missing_columns = [col for col in required_columns if col not in df.columns]

    if missing_columns:
        print(f"  âŒ ä¸è¶³ã‚«ãƒ©ãƒ : {', '.join(missing_columns)}")
        return False

    print(f"  âœ… å¿…é ˆã‚«ãƒ©ãƒ : ã™ã¹ã¦å­˜åœ¨")

    # latitude/longitudeåˆ—ã®ç¢ºèªï¼ˆMAPçµ±åˆå¯¾å¿œï¼‰
    has_coords = df[['latitude', 'longitude']].notna().all(axis=1).sum()
    total = len(df)
    print(f"  ğŸ—ºï¸ åº§æ¨™ãƒ‡ãƒ¼ã‚¿: {has_coords}/{total}ä»¶ ({has_coords/total*100:.1f}%)")

    # ã‚µãƒ³ãƒ—ãƒ«ãƒ‡ãƒ¼ã‚¿è¡¨ç¤ºï¼ˆæœ€ã‚‚ç«¶äº‰ãŒæ¿€ã—ã„åœ°åŸŸï¼‰
    print(f"\n  ã€Top 5 ç«¶äº‰ãŒæ¿€ã—ã„åœ°åŸŸã€‘")
    print(df[['location', 'total_applicants', 'top_age_group', 'female_ratio', 'national_license_rate']].head().to_string(index=False))

    # å“è³ªãƒ¬ãƒãƒ¼ãƒˆç¢ºèª
    report_df = pd.read_csv(quality_report, encoding='utf-8-sig')
    print(f"\n  âœ… P14_QualityReport.csv: {len(report_df)}é …ç›®")

    return True


def main():
    """ãƒ¡ã‚¤ãƒ³å‡¦ç†"""
    print("=" * 80)
    print("Phase 12, 13, 14çµ±åˆãƒ†ã‚¹ãƒˆ")
    print("=" * 80)

    results = {}

    # Phase 12ãƒ†ã‚¹ãƒˆ
    results['Phase 12'] = test_phase12_supply_demand_gap()

    # Phase 13ãƒ†ã‚¹ãƒˆ
    results['Phase 13'] = test_phase13_rarity_score()

    # Phase 14ãƒ†ã‚¹ãƒˆ
    results['Phase 14'] = test_phase14_competition_profile()

    # æœ€çµ‚çµæœ
    print("\n" + "=" * 80)
    print("ã€ãƒ†ã‚¹ãƒˆçµæœã‚µãƒãƒªãƒ¼ã€‘")
    print("=" * 80)

    for phase, passed in results.items():
        status = "âœ… PASS" if passed else "âŒ FAIL"
        print(f"  {phase}: {status}")

    all_passed = all(results.values())
    print("\n" + "=" * 80)
    if all_passed:
        print("âœ… ã™ã¹ã¦ã®ãƒ†ã‚¹ãƒˆãŒPASSã—ã¾ã—ãŸï¼")
    else:
        print("âŒ ä¸€éƒ¨ã®ãƒ†ã‚¹ãƒˆãŒFAILã—ã¾ã—ãŸ")
    print("=" * 80)

    return all_passed


if __name__ == '__main__':
    success = main()
    sys.exit(0 if success else 1)
