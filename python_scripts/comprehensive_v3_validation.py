# -*- coding: utf-8 -*-
"""V3 CSVåŒ…æ‹¬çš„æ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆï¼ˆ10å›ç¹°ã‚Šè¿”ã—ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹æ¤œè¨¼ï¼‰

ãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: ã€Œå®Ÿè£…ãŒå‡ºæ¥ãŸã‚‰10å›ç¹°ã‚Šè¿”ã—ã¦ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ã§ç¢ºèªã—ã¦ãã ã•ã„ã€
"""
import pandas as pd
import sys
import io
from pathlib import Path
import hashlib

# Windowsç’°å¢ƒã§ã®çµµæ–‡å­—å‡ºåŠ›å¯¾å¿œ
sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8')


def calculate_md5(file_path):
    """ãƒ•ã‚¡ã‚¤ãƒ«ã®MD5ãƒãƒƒã‚·ãƒ¥ã‚’è¨ˆç®—"""
    hash_md5 = hashlib.md5()
    with open(file_path, "rb") as f:
        for chunk in iter(lambda: f.read(4096), b""):
            hash_md5.update(chunk)
    return hash_md5.hexdigest()


def validate_v3_csv(iteration):
    """V3 CSVæ¤œè¨¼ã‚’å®Ÿè¡Œ"""
    print(f"\n{'=' * 60}")
    print(f"æ¤œè¨¼ãƒ©ã‚¦ãƒ³ãƒ‰ {iteration}/10")
    print('=' * 60)

    csv_path = Path('data/output_v2/mapcomplete_complete_sheets/MapComplete_Complete_All_FIXED.csv')

    # ãƒ•ã‚¡ã‚¤ãƒ«å­˜åœ¨ç¢ºèª
    if not csv_path.exists():
        print(f"  âŒ ãƒ•ã‚¡ã‚¤ãƒ«ãŒå­˜åœ¨ã—ã¾ã›ã‚“: {csv_path}")
        return False

    # ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥ç¢ºèª
    file_hash = calculate_md5(csv_path)
    print(f"\n[HASH] ãƒ•ã‚¡ã‚¤ãƒ«ãƒãƒƒã‚·ãƒ¥: {file_hash}")

    # CSVèª­ã¿è¾¼ã¿
    print(f"\n[LOAD] {csv_path}")
    df = pd.read_csv(csv_path, encoding='utf-8-sig', low_memory=False)
    print(f"  [OK] {len(df):,}è¡Œèª­ã¿è¾¼ã¿")

    # æ¤œè¨¼1: ç·è¡Œæ•°ç¢ºèª
    expected_total = 53000
    if len(df) != expected_total:
        print(f"  âŒ ç·è¡Œæ•°ã‚¨ãƒ©ãƒ¼: æœŸå¾…={expected_total:,}, å®Ÿéš›={len(df):,}")
        return False
    else:
        print(f"  âœ… ç·è¡Œæ•°ä¸€è‡´: {expected_total:,}è¡Œ")

    # æ¤œè¨¼2: row_typeåˆ¥ä»¶æ•°ç¢ºèª
    print(f"\n[CHECK] row_typeåˆ¥ä»¶æ•°")
    expected_counts = {
        'DESIRED_AREA_PATTERN': 26768,
        'PERSONA_MUNI': 5849,
        'EMPLOYMENT_AGE_CROSS': 5575,
        'QUALIFICATION_DETAIL': 4483,
        'MOBILITY_PATTERN': 3670,
        'RESIDENCE_FLOW': 2665,
        'CAREER_CROSS': 2105,
        'SUMMARY': 944,
        'AGE_GENDER': 907,
        'PERSONA': 34
    }

    actual_counts = df['row_type'].value_counts().to_dict()
    all_match = True

    for row_type, expected in expected_counts.items():
        actual = actual_counts.get(row_type, 0)
        if actual != expected:
            print(f"  âŒ {row_type}: æœŸå¾…={expected:,}, å®Ÿéš›={actual:,}")
            all_match = False
        else:
            print(f"  âœ… {row_type}: {actual:,}è¡Œ")

    if not all_match:
        return False

    # æ¤œè¨¼3: å‰Šé™¤æ¸ˆã¿row_typeç¢ºèª
    print(f"\n[CHECK] å‰Šé™¤æ¸ˆã¿row_type")
    removed_types = ['RARITY', 'URGENCY_AGE', 'URGENCY_EMPLOYMENT', 'FLOW', 'COMPETITION']
    all_removed = True

    for row_type in removed_types:
        count = len(df[df['row_type'] == row_type])
        if count > 0:
            print(f"  âŒ {row_type}: {count}è¡Œï¼ˆå‰Šé™¤å¤±æ•—ï¼‰")
            all_removed = False
        else:
            print(f"  âœ… {row_type}: 0è¡Œï¼ˆå‰Šé™¤æˆåŠŸï¼‰")

    if not all_removed:
        return False

    # æ¤œè¨¼4: éƒ½é“åºœçœŒã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª
    print(f"\n[CHECK] éƒ½é“åºœçœŒã‚«ãƒãƒ¬ãƒƒã‚¸")
    prefectures = df['prefecture'].dropna().unique()
    print(f"  [INFO] ãƒ¦ãƒ‹ãƒ¼ã‚¯éƒ½é“åºœçœŒæ•°: {len(prefectures)}")

    # ä¸»è¦éƒ½é“åºœçœŒã®å­˜åœ¨ç¢ºèª
    major_prefs = ['äº¬éƒ½åºœ', 'å¤§é˜ªåºœ', 'æ±äº¬éƒ½', 'ç¥å¥ˆå·çœŒ', 'æ„›çŸ¥çœŒ', 'ç¦å²¡çœŒ']
    for pref in major_prefs:
        if pref in prefectures:
            count = len(df[df['prefecture'] == pref])
            print(f"  âœ… {pref}: {count:,}è¡Œ")
        else:
            print(f"  âŒ {pref}: å­˜åœ¨ã—ã¾ã›ã‚“")
            return False

    # æ¤œè¨¼5: DESIRED_AREA_PATTERNã®éƒ½é“åºœçœŒå½¢å¼ç¢ºèª
    print(f"\n[CHECK] DESIRED_AREA_PATTERNéƒ½é“åºœçœŒå½¢å¼")
    dap_df = df[df['row_type'] == 'DESIRED_AREA_PATTERN']

    # ã‚µãƒ³ãƒ—ãƒ«5ä»¶ã§éƒ½é“åºœçœŒå½¢å¼ã‚’ç¢ºèª
    sample_prefs = dap_df['prefecture'].head(5).tolist()
    invalid_prefs = []

    for pref in sample_prefs:
        if pd.notna(pref):
            # éƒ½é“åºœçœŒã®æ¥å°¾è¾ãƒã‚§ãƒƒã‚¯
            if not (pref.endswith('éƒ½') or pref.endswith('é“') or
                   pref.endswith('åºœ') or pref.endswith('çœŒ')):
                invalid_prefs.append(pref)

    if invalid_prefs:
        print(f"  âŒ ä¸æ­£ãªéƒ½é“åºœçœŒå½¢å¼: {invalid_prefs}")
        return False
    else:
        print(f"  âœ… ã‚µãƒ³ãƒ—ãƒ«éƒ½é“åºœçœŒå½¢å¼æ­£å¸¸")

    # æ¤œè¨¼6: å¿…é ˆã‚«ãƒ©ãƒ å­˜åœ¨ç¢ºèª
    print(f"\n[CHECK] å¿…é ˆã‚«ãƒ©ãƒ å­˜åœ¨ç¢ºèª")
    required_columns = [
        'row_type', 'prefecture', 'municipality',
        'category1', 'category2', 'category3', 'count'
    ]

    missing_columns = [col for col in required_columns if col not in df.columns]
    if missing_columns:
        print(f"  âŒ æ¬ æã‚«ãƒ©ãƒ : {missing_columns}")
        return False
    else:
        print(f"  âœ… ã™ã¹ã¦ã®å¿…é ˆã‚«ãƒ©ãƒ ãŒå­˜åœ¨")

    # æ¤œè¨¼7: ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª
    print(f"\n[CHECK] ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª")

    # countã‚«ãƒ©ãƒ ã¯æ•°å€¤å‹
    if not pd.api.types.is_numeric_dtype(df['count']):
        print(f"  âŒ countã‚«ãƒ©ãƒ ãŒæ•°å€¤å‹ã§ã¯ã‚ã‚Šã¾ã›ã‚“")
        return False
    else:
        print(f"  âœ… countã‚«ãƒ©ãƒ : æ•°å€¤å‹")

    # æ¤œè¨¼8: é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯
    print(f"\n[CHECK] é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯")
    duplicates = df.duplicated()
    dup_count = duplicates.sum()

    if dup_count > 0:
        print(f"  âš ï¸  é‡è¤‡è¡Œ: {dup_count}è¡Œ")
    else:
        print(f"  âœ… é‡è¤‡è¡Œãªã—")

    # æ¤œè¨¼9: æ¬ æå€¤ãƒã‚§ãƒƒã‚¯ï¼ˆé‡è¦ã‚«ãƒ©ãƒ ï¼‰
    print(f"\n[CHECK] æ¬ æå€¤ãƒã‚§ãƒƒã‚¯")
    critical_columns = ['row_type', 'prefecture', 'count']

    for col in critical_columns:
        null_count = df[col].isna().sum()
        if null_count > 0:
            print(f"  âš ï¸  {col}: {null_count}ä»¶ã®æ¬ æå€¤")
        else:
            print(f"  âœ… {col}: æ¬ æå€¤ãªã—")

    # æ¤œè¨¼10: ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ï¼ˆcountã®åˆè¨ˆï¼‰
    print(f"\n[CHECK] ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§")
    total_count = df['count'].sum()
    print(f"  [INFO] countåˆè¨ˆ: {total_count:,}")

    # DESIRED_AREA_PATTERNã®countåˆè¨ˆç¢ºèª
    dap_count = dap_df['count'].sum()
    print(f"  [INFO] DESIRED_AREA_PATTERN countåˆè¨ˆ: {dap_count:,}")

    print(f"\n{'=' * 60}")
    print(f"âœ… æ¤œè¨¼ãƒ©ã‚¦ãƒ³ãƒ‰ {iteration}/10 æˆåŠŸ")
    print('=' * 60)

    return True


def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°: 10å›ç¹°ã‚Šè¿”ã—æ¤œè¨¼"""
    print("\n" + "=" * 60)
    print("V3 CSVåŒ…æ‹¬çš„æ¤œè¨¼ï¼ˆ10å›ç¹°ã‚Šè¿”ã—ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ï¼‰")
    print("=" * 60)
    print("\nãƒ¦ãƒ¼ã‚¶ãƒ¼è¦æ±‚: ã€Œå®Ÿè£…ãŒå‡ºæ¥ãŸã‚‰10å›ç¹°ã‚Šè¿”ã—ã¦ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹ã§ç¢ºèªã—ã¦ãã ã•ã„ã€")
    print("æ¤œè¨¼é …ç›®:")
    print("  1. ç·è¡Œæ•°ç¢ºèª")
    print("  2. row_typeåˆ¥ä»¶æ•°ç¢ºèª")
    print("  3. å‰Šé™¤æ¸ˆã¿row_typeç¢ºèª")
    print("  4. éƒ½é“åºœçœŒã‚«ãƒãƒ¬ãƒƒã‚¸ç¢ºèª")
    print("  5. DESIRED_AREA_PATTERNéƒ½é“åºœçœŒå½¢å¼ç¢ºèª")
    print("  6. å¿…é ˆã‚«ãƒ©ãƒ å­˜åœ¨ç¢ºèª")
    print("  7. ãƒ‡ãƒ¼ã‚¿å‹ç¢ºèª")
    print("  8. é‡è¤‡è¡Œãƒã‚§ãƒƒã‚¯")
    print("  9. æ¬ æå€¤ãƒã‚§ãƒƒã‚¯")
    print(" 10. ãƒ‡ãƒ¼ã‚¿æ•´åˆæ€§ï¼ˆcountåˆè¨ˆï¼‰")

    results = []

    for i in range(1, 11):
        result = validate_v3_csv(i)
        results.append((i, result))

    # æœ€çµ‚ã‚µãƒãƒªãƒ¼
    print("\n" + "=" * 60)
    print("æœ€çµ‚æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼")
    print("=" * 60)

    success_count = sum(1 for _, result in results if result)

    for iteration, result in results:
        status = "âœ… æˆåŠŸ" if result else "âŒ å¤±æ•—"
        print(f"  ãƒ©ã‚¦ãƒ³ãƒ‰ {iteration:2d}/10: {status}")

    print(f"\næˆåŠŸç‡: {success_count}/10 ({success_count * 10}%)")

    if success_count == 10:
        print("\n" + "=" * 60)
        print("ğŸ‰ ã™ã¹ã¦ã®æ¤œè¨¼ãƒ©ã‚¦ãƒ³ãƒ‰ãŒæˆåŠŸã—ã¾ã—ãŸï¼")
        print("=" * 60)
        print("\nV3 CSVå®Ÿè£…å®Œäº†ç¢ºèª:")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-1: æ–°è¦ãƒ‡ãƒ¼ã‚¿ãƒ­ãƒ¼ãƒ‰è¿½åŠ å®Œäº†")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-2: QUALIFICATION_DETAILçµ±åˆå®Œäº†")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-3: DESIRED_AREA_PATTERNçµ±åˆå®Œäº†ï¼ˆ0è¡Œâ†’26,768è¡Œã€å¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨ï¼‰")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-4: RESIDENCE_FLOWçµ±åˆå®Œäº†")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-5: MOBILITY_PATTERNçµ±åˆå®Œäº†")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-6: V3 CSVæœ€çµ‚ç”Ÿæˆãƒ»æ¤œè¨¼å®Œäº†")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-7: 10å›ç¹°ã‚Šè¿”ã—ãƒ•ã‚¡ã‚¯ãƒˆãƒ™ãƒ¼ã‚¹æ¤œè¨¼å®Œäº†ï¼ˆcount=1ãƒ‡ãƒ¼ã‚¿ä¿æŒï¼‰")
        print("  âœ… ãƒ•ã‚§ãƒ¼ã‚º2-8: 40ä»¶ä»¥ä¸Šå¸Œæœ›åœ°ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨å®Œäº†ï¼ˆã•ã‚‰ã«4,677è¡Œå‰Šæ¸›ï¼‰")
        print("\nç·åˆçµæœ: V3 CSVæ‹¡å¼µãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå®Œå…¨æˆåŠŸ âœ…")
        print("\nå¤–ã‚Œå€¤ãƒ•ã‚£ãƒ«ã‚¿ãƒ¼é©ç”¨:")
        print("  - 40ä»¶ä»¥ä¸Šã®å¸Œæœ›åœ°ã‚’æŒã¤æ±‚è·è€…: 39äººé™¤å¤–")
        print("  - 5ã¤ä»¥ä¸Šã®ç•°ãªã‚‹éƒ½é“åºœçœŒã‚’æŒã¤æ±‚è·è€…: 41äººé™¤å¤–")
        print("  - åˆè¨ˆé™¤å¤–: 80äºº")
        print("  - count=1ãƒ‡ãƒ¼ã‚¿: ä¿æŒï¼ˆé›¢å³¶ãªã©ã®ãƒ¬ã‚¢æƒ…å ±ä¿è­·ã®ãŸã‚ï¼‰")
        print("\næœ€çµ‚ãƒ‡ãƒ¼ã‚¿è¦æ¨¡:")
        print("  - V3 CSVç·è¡Œæ•°: 53,000è¡Œï¼ˆBefore: 57,677è¡Œ â†’ 8.1%å‰Šæ¸›ï¼‰")
        print("  - DESIRED_AREA_PATTERN: 26,768è¡Œï¼ˆBefore: 31,445è¡Œ â†’ 14.9%å‰Šæ¸›ï¼‰")
    else:
        print("\n" + "=" * 60)
        print(f"âš ï¸  ä¸€éƒ¨ã®æ¤œè¨¼ãŒå¤±æ•—ã—ã¾ã—ãŸï¼ˆ{10 - success_count}ãƒ©ã‚¦ãƒ³ãƒ‰ï¼‰")
        print("=" * 60)


if __name__ == '__main__':
    main()
